<!-- Generated by SpecStory -->

# CSV to SparkSQL Conversion Guide (2025-05-20 10:00:06)

_**User**_

帮我改写一下这个 csv 为 sparkSQL ：
目标表	目标Column	data_source_name	source column	key path
risk.dwd_risk_id_af_vida_di	credit_user_id	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	header_data	
risk.dwd_risk_id_af_vida_di	request_key	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	request_key	
risk.dwd_risk_id_af_vida_di	data_source_name	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	data_source_name	
risk.dwd_risk_id_af_vida_di	data_source_code	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	data_source_code	
risk.dwd_risk_id_af_vida_di	kyc_event_id	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	resp_raw_data	resp_raw_data.data.transactionId
risk.dwd_risk_id_af_vida_di	kyc_status_raw	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	resp_raw_data	resp_raw_data.data.statusCode
risk.dwd_risk_id_af_vida_di	score_pob	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_full_name	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		"-- To get the 'result' where 'name' is 'full_name':
SELECT platform_user_id, ar.result * 10 AS full_name_result -- the result range is [0,1], transform to [0,10] to match with old logic
FROM identity_data_history_tab
CROSS JOIN UNNEST(CAST(json_extract(resp_raw_data, '$.data.assessmentResults') AS ARRAY(ROW(name VARCHAR, result DOUBLE)))) AS ar
WHERE ar.name = 'full_name'"
risk.dwd_risk_id_af_vida_di	score_address	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_province	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_city	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_dob	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		"-- To get the 'result' where 'name' is 'dob':
SELECT platform_user_id, ar.result * 10 AS dob_result -- the result range is [0,1], transform to [0,10] to match with old logic
FROM identity_data_history_tab
CROSS JOIN UNNEST(CAST(json_extract(resp_raw_data, '$.data.assessmentResults') AS ARRAY(ROW(name VARCHAR, result DOUBLE)))) AS ar
WHERE ar.name = 'dob'"
risk.dwd_risk_id_af_vida_di	score_district	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_village	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_nik	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		"-- To get the 'result' where 'name' is 'nik':
SELECT platform_user_id, ar.result * 10 AS nik_result -- the result range is [0,1], transform to [0,10] to match with old logic
FROM identity_data_history_tab
CROSS JOIN UNNEST(CAST(json_extract(resp_raw_data, '$.data.assessmentResults') AS ARRAY(ROW(name VARCHAR, result DOUBLE)))) AS ar
WHERE ar.name = 'nik'"
risk.dwd_risk_id_af_vida_di	score_mother_maiden_name	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_family_card_no	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_demographic	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	score_selfiephoto	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		"-- To get the 'result' where 'name' is 'selfiePhoto':
SELECT platform_user_id, ar.result * 10 AS selfiePhoto_result -- the result range is [0,1], transform to [0,10] to match with old logic
FROM identity_data_history_tab
CROSS JOIN UNNEST(CAST(json_extract(resp_raw_data, '$.data.assessmentResults') AS ARRAY(ROW(name VARCHAR, result DOUBLE)))) AS ar
WHERE ar.name = 'selfiePhoto'"
risk.dwd_risk_id_af_vida_di	score_liveness	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		Null
risk.dwd_risk_id_af_vida_di	trace_id	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	trace_id	
risk.dwd_risk_id_af_vida_di	create_time	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	create_time	
risk.dwd_risk_id_af_vida_di	update_time	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew	update_time	
risk.dwd_risk_id_af_vida_di	grass_date	VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew		

参考 @VidaCfFr.sql 的语法，不要参考里面的参数！只是语法

---

_**Assistant**_



---

我将根据您提供的CSV内容和参考的SQL语法创建新的SparkSQL代码。

---

```diff
- 
+ -- 将 ODS 表中的 VidaCfFullNew/VidaCfFrNew/VidaCfDemogNew/VidaLdnFullNew 数据写入 DWD 表
+ -- INSERT INTO TABLE risk.dwd_risk_id_af_vida_di
+ WITH exploded_assessment_results AS (
+   SELECT 
+     resp_raw_data,
+     header_data,
+     request_key,
+     data_source_name,
+     data_source_code,
+     trace_id,
+     create_time,
+     update_time,
+     assessment_obj.name AS assessment_name,
+     assessment_obj.result * 10 AS assessment_score -- 将[0,1]范围转换为[0,10]范围
+   FROM risk.ods__credit_risk_datafetch_id_db__identity_data_tab__df
+   LATERAL VIEW EXPLODE(
+     FROM_JSON(
+       get_json_object(resp_raw_data, '$.data.assessmentResults'),
+       'array<struct<name:string,result:double>>'
+     )
+   ) assessments AS assessment_obj
+   WHERE data_source_name IN ('VidaCfFullNew', 'VidaCfFrNew', 'VidaCfDemogNew', 'VidaLdnFullNew') 
+     AND grass_date = '${ds}'
+ )
+ SELECT
+   get_json_object(t.header_data, '$.CreditUserId') AS credit_user_id,
+   t.request_key AS request_key,
+   t.data_source_name AS data_source_name,
+   t.data_source_code AS data_source_code,
+   get_json_object(t.resp_raw_data, '$.data.transactionId') AS kyc_event_id,
+   get_json_object(t.resp_raw_data, '$.data.statusCode') AS kyc_status_raw,
+   NULL AS score_pob,
+   MAX(CASE WHEN a.assessment_name = 'full_name' THEN a.assessment_score ELSE NULL END) AS score_full_name,
+   NULL AS score_address,
+   NULL AS score_province,
+   NULL AS score_city,
+   MAX(CASE WHEN a.assessment_name = 'dob' THEN a.assessment_score ELSE NULL END) AS score_dob,
+   NULL AS score_district,
+   NULL AS score_village,
+   MAX(CASE WHEN a.assessment_name = 'nik' THEN a.assessment_score ELSE NULL END) AS score_nik,
+   NULL AS score_mother_maiden_name,
+   NULL AS score_family_card_no,
+   NULL AS score_demographic,
+   MAX(CASE WHEN a.assessment_name = 'selfiePhoto' THEN a.assessment_score ELSE NULL END) AS score_selfiephoto,
+   NULL AS score_liveness,
+   t.trace_id AS trace_id,
+   t.create_time AS create_time,
+   t.update_time AS update_time,
+   '${ds}' AS grass_date
+ FROM (
+   SELECT 
+     resp_raw_data,
+     header_data,
+     request_key,
+     data_source_name,
+     data_source_code,
+     trace_id,
+     create_time,
+     update_time
+   FROM risk.ods__credit_risk_datafetch_id_db__identity_data_tab__df
+   WHERE data_source_name IN ('VidaCfFullNew', 'VidaCfFrNew', 'VidaCfDemogNew', 'VidaLdnFullNew')
+     AND grass_date = '${ds}'
+ ) t
+ LEFT JOIN exploded_assessment_results a
+ ON t.resp_raw_data = a.resp_raw_data
+ AND t.header_data = a.header_data
+ AND t.request_key = a.request_key
+ AND t.data_source_code = a.data_source_code
+ GROUP BY
+   t.resp_raw_data,
+   t.header_data,
+   t.request_key,
+   t.data_source_name,
+   t.data_source_code,
+   t.trace_id,
+   t.create_time,
+   t.update_time
+ ;
  
```

---

已经将CSV内容转换为SparkSQL代码并保存到new.sql文件中。这个SQL主要做了以下工作：

1. 创建了一个临时表（CTE）`exploded_assessment_results`，用于展开JSON中的评估结果数组
2. 使用`LATERAL VIEW EXPLODE`和`FROM_JSON`解析嵌套的JSON数据
3. 将原始JSON结果得分从[0,1]范围转换为[0,10]范围
4. 通过`MAX(CASE WHEN...)`模式获取各个评估项目的得分
5. 使用LEFT JOIN将主查询与评估结果连接
6. 按照CSV中的映射关系提取和转换所有所需字段

SQL中使用了与参考文件相似的结构，但根据CSV中提供的关键路径进行了适当调整，特别是JSON路径的处理。

---

_**User**_

select 
     kyc_event_id
     ,get_json_object(tbl.fields,'$.field') field
     ,get_json_object(tbl.fields,'$.score') score
     from (
           select 
           get_json_object(t1.resp_raw_data, '$.data.eventId') as kyc_event_id
           ,get_json_object(t1.resp_raw_data, '$.data.fields') as fields
           from risk.ods__credit_risk_datafetch_id_db__identity_data_tab__df t1
           where grass_date ='${ds}'
           and data_source_name in('VidaCfFr','VidaCfDemog')
     ) a 
     lateral view explode(json_to_array(fields)) tbl as fields 
     where get_json_object(tbl.fields,'$.field')='liveness'
可以参考这个 改一下 with 的 临时表吗？

---

_**Assistant**_



---

我将根据您提供的示例修改SQL中的临时表部分。

---



---



---

